import pandas as pd
import requests
from bs4 import BeautifulSoup
import time
from concurrent.futures import ThreadPoolExecutor, as_completed

# ×§×‘×¦×™× ×•×”×’×“×¨×•×ª
FILENAME = "jw.xlsx"
SHEET_NAME = "×’×™×œ×™×•×Ÿ2"
FIELDS = ["CustomerID", "Biography"]
OUTPUT_FILE = "jw_updated_only.xlsx"
SAVE_EVERY = 500
MAX_WORKERS = 10

print(f"ğŸ“‚ ×˜×•×¢×Ÿ ××ª ×”×§×•×‘×¥: {FILENAME}, ×’×™×œ×™×•×Ÿ: {SHEET_NAME}")
df = pd.read_excel(FILENAME, sheet_name=SHEET_NAME, usecols=FIELDS)

# ×–×™×”×•×™ ×‘×™×•×’×¨×¤×™×” ×¤×’×•××”
def is_corrupted_bio(bio):
    if not isinstance(bio, str):
        return False
    bio = bio.strip()
    if not bio:
        return False
    signs = ["<p", "<span", "&quot;", "&nbsp;", "&#", "style=", "font-", "color:", "<br"]
    return any(sign in bio.lower() for sign in signs) or len(bio) < 100

# ×©×œ×™×¤×ª ×‘×™×•×’×¨×¤×™×” ××”××ª×¨
def fetch_biography(customer_id):
    url = f"https://www.jwmww2.org/soldier.aspx?id={int(customer_id)}"
    try:
        response = requests.get(url, timeout=10)
        response.raise_for_status()
        soup = BeautifulSoup(response.text, "html.parser")

        # × ×™×¡×™×•×Ÿ ×œ×¤×™ ××‘× ×” ×™×©×Ÿ
        bio_div = soup.find("div", id="ContentPlaceHolder1_lblBio")
        if bio_div and bio_div.get_text(strip=True):
            time.sleep(0.1)
            return bio_div.get_text(separator="\n").strip()

        # × ×™×¡×™×•×Ÿ ×œ×¤×™ ××‘× ×” ×—×“×©
        bio_new = soup.find("p", id="mainContent_txtBody2")
        if bio_new and bio_new.get_text(strip=True):
            time.sleep(0.1)
            return bio_new.get_text(separator="\n").strip()

    except Exception as e:
        print(f"âŒ ×©×’×™××” ×‘-ID {customer_id}: {e}")
    return None

# ×¡×™× ×•×Ÿ ×©×•×¨×•×ª ×—×©×•×“×•×ª
corrupted_df = df[df["Biography"].apply(is_corrupted_bio)]
print(f"\nğŸ” ×©×•×¨×•×ª ×—×©×•×“×•×ª ×œ×¡×¨×™×§×”: {len(corrupted_df)}")

# ×¨×©×™××ª ×ª×•×¦××•×ª ×ª×§×™× ×•×ª
updated_rows = []

# ×¤×•× ×§×¦×™×™×ª ×¢×™×‘×•×“ ×œ×œ×•×—×
def process_row(index, row):
    cid = row["CustomerID"]
    old_bio = row["Biography"]
    new_bio = fetch_biography(cid)
    if new_bio:
        new_row = row.copy()
        new_row["Biography"] = new_bio
        print(f"âœ… ×¢×“×›×•×Ÿ ×œ×•×—× ID {cid}")
        return new_row
    else:
        print(f"âš ï¸ ×œ×œ× ×¢×“×›×•×Ÿ ×œ×•×—× ID {cid}")
    return None

# ×”×¨×¦×” ×¢× ThreadPool
with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
    futures = {executor.submit(process_row, i, row): i for i, row in corrupted_df.iterrows()}

    for count, future in enumerate(as_completed(futures), 1):
        result = future.result()
        if result is not None:
            updated_rows.append(result)

        # ×©××™×¨×” ×›×œ 500
        if count % SAVE_EVERY == 0 and updated_rows:
            partial_df = pd.DataFrame(updated_rows)
            partial_df.to_excel(OUTPUT_FILE, index=False)
            print(f"\nğŸ’¾ × ×©××¨ ×§×•×‘×¥ ×–×× ×™: {OUTPUT_FILE} ({len(updated_rows)} ×©×•×¨×•×ª ××¢×•×“×›× ×•×ª)\n")

# ×©××™×¨×” ×¡×•×¤×™×ª
if updated_rows:
    final_df = pd.DataFrame(updated_rows)
    final_df.to_excel(OUTPUT_FILE, index=False)
    print(f"\nâœ… × ×©××¨ ×§×•×‘×¥ ×¡×•×¤×™ ×¢× {len(updated_rows)} ×‘×™×•×’×¨×¤×™×•×ª ××ª×•×§× ×•×ª: {OUTPUT_FILE}")
else:
    print("â— ×œ× × ××¦××• ×‘×™×•×’×¨×¤×™×•×ª ×ª×§×™× ×•×ª â€“ ×œ× × ×©××¨ ×§×•×‘×¥.")

print("\nğŸ‰ ×¡×™×•× ××œ×!")
